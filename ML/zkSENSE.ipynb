{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "import glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "        (['uac_mean1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_mean1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_mean1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_mean2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_mean2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_mean2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_std1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_std1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_std1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_std2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_std2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_std2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_mean1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_mean1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_mean1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_mean2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_mean2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_mean2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_std1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_std1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_std1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_std2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_std2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['uac_dev_std2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_mean1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_mean1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_mean1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_mean2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_mean2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_mean2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_std1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_std1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_std1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_std2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_std2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_std2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_mean1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_mean1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_mean1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_mean2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_mean2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_mean2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_std1_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_std1_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_std1_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_std2_x'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_std2_y'], sklearn.preprocessing.StandardScaler()),\n",
    "        (['gyr_dev_std2_z'], sklearn.preprocessing.StandardScaler()),\n",
    "        ('label', sklearn.preprocessing.LabelBinarizer())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_labelled_data(data_folder=\"data/LabelledData\"):\n",
    "    df_list = []\n",
    "\n",
    "    for data_file in glob2.glob(\"{}/*.csv\".format(data_folder)):\n",
    "        df_list.append(pd.read_csv(data_file).iloc[:,1:])\n",
    "\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    for sensor in ['uac', 'gyr']:\n",
    "        for axis in ['x', 'y', 'z', 'amp']:\n",
    "#             df[f'{sensor}_relative_gap_{axis}'] = df[f'{sensor}_gap_{axis}'] / df['touch_duration']\n",
    "            df[f'{sensor}_diff_{axis}'] = df[f'{sensor}_max_{axis}'] - df[f'{sensor}_min_{axis}']\n",
    "            df[f'{sensor}_dev_diff_{axis}'] = df[f'{sensor}_dev_max_{axis}'] - df[f'{sensor}_dev_min_{axis}']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def print_evaluation_result(clf, X, y, cv=10):\n",
    "    metrics = ['accuracy', 'balanced_accuracy', 'f1', 'f1_weighted', 'recall']\n",
    "#     metrics = ['balanced_accuracy', 'f1', 'f1_weighted', 'recall']\n",
    "    \n",
    "    for scoring in metrics:\n",
    "        scores = cross_val_score(clf, X, y, cv=cv, scoring=scoring, error_score='raise')\n",
    "        \n",
    "        print(\"Scoring Metric: {}\\n---------\".format(scoring))\n",
    "        print(\"Scores: {}\".format(scores))\n",
    "        print(\"{}: {:.2f} (+/- {:.2f})\\n\".format(scoring, scores.mean(), scores.std() * 2))\n",
    "\n",
    "        \n",
    "def get_processd_data(df):\n",
    "    data = mapper.fit_transform(df.copy())\n",
    "    X = data[:, :-1]\n",
    "    y = 1 - data[:, -1]  # Flip 0 and 1 so Bot is with positive label\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_processed_posture_data(df):\n",
    "    rest_df = df[df['remark'].str.contains('Desk') | df['remark'].str.contains('Stand')]\n",
    "    rest_df = rest_df.assign(label=\"Rest\")\n",
    "    handheld_df = df[df['remark'].str.contains('Handheld')]\n",
    "    handheld_df = handheld_df.assign(label=\"Handheld\")\n",
    "\n",
    "    posture_df = pd.concat([rest_df, handheld_df])\n",
    "    posture_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return get_processd_data(posture_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_labelled_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Processed Bot Detection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_processd_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 7\n",
      "-----------\n",
      "Scores: [0.81492734 0.92562984 0.9426859  0.91349053 0.88374785 0.94238085\n",
      " 0.93381965 0.97240215 0.96750001 0.94426153]\n",
      "Accuracy: 0.92 (+/- 0.09)\n",
      "\n",
      "Max Depth: 8\n",
      "-----------\n",
      "Scores: [0.83107721 0.92595733 0.93335935 0.91542851 0.9003553  0.95407605\n",
      " 0.94235323 0.97971018 0.97396832 0.95354374]\n",
      "Accuracy: 0.93 (+/- 0.08)\n",
      "\n",
      "Max Depth: 9\n",
      "-----------\n",
      "Scores: [0.83908949 0.92220697 0.93921368 0.9223909  0.90482791 0.95343005\n",
      " 0.94743678 0.98061804 0.97462663 0.95807156]\n",
      "Accuracy: 0.93 (+/- 0.08)\n",
      "\n",
      "Max Depth: 10\n",
      "-----------\n",
      "Scores: [0.84574226 0.92576443 0.93410404 0.87847671 0.91011251 0.96750736\n",
      " 0.93885804 0.97971018 0.97488765 0.95792382]\n",
      "Accuracy: 0.93 (+/- 0.08)\n",
      "\n",
      "Max Depth: 11\n",
      "-----------\n",
      "Scores: [0.8337287  0.92124246 0.94640935 0.91620909 0.90404734 0.97603987\n",
      " 0.9394934  0.97796259 0.95860359 0.95778757]\n",
      "Accuracy: 0.93 (+/- 0.08)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-d5c6e5caabc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max Depth: {}\\n-----------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for max_depth in range(7, 15):\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=0)\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='balanced_accuracy')\n",
    "    \n",
    "    print(\"Max Depth: {}\\n-----------\".format(max_depth))\n",
    "    print(\"Scores: {}\".format(scores))\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.8960499  0.93939394 0.91622103 0.90849673 0.85888295 0.98425431\n",
      " 0.97384844 0.94175334 0.97711738 0.94086181]\n",
      "accuracy: 0.93 (+/- 0.08)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.77616765 0.9076362  0.92521264 0.88485591 0.89659148 0.96984012\n",
      " 0.94943392 0.92814666 0.96698943 0.94481727]\n",
      "balanced_accuracy: 0.91 (+/- 0.11)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.93666305 0.96087457 0.94350962 0.93986724 0.90023104 0.9898448\n",
      " 0.98321892 0.96185286 0.9851552  0.96066416]\n",
      "f1: 0.96 (+/- 0.05)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.88461904 0.93896942 0.91923219 0.90970479 0.86775674 0.98412498\n",
      " 0.97347009 0.94233411 0.97710176 0.94234314]\n",
      "f1_weighted: 0.93 (+/- 0.07)\n",
      "\n",
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [0.99807173 0.96643519 0.90856481 0.92862654 0.82677469 0.99652778\n",
      " 0.99459877 0.9533179  0.98572531 0.9375    ]\n",
      "recall: 0.95 (+/- 0.10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=9, random_state=0)\n",
    "print_evaluation_result(clf, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3\n",
      "-----------\n",
      "Scores: [0.84476841 0.941044   0.935405   0.91065533 0.90102372 0.97099752\n",
      " 0.95985134 0.96417477 0.97429747 0.96135088]\n",
      "Accuracy: 0.94 (+/- 0.08)\n",
      "\n",
      "Max Depth: 4\n",
      "-----------\n",
      "Scores: [0.85232752 0.9364368  0.92628481 0.92447692 0.90313666 0.97151791\n",
      " 0.96069107 0.96304032 0.97720247 0.96606011]\n",
      "Accuracy: 0.94 (+/- 0.07)\n",
      "\n",
      "Max Depth: 5\n",
      "-----------\n",
      "Scores: [0.84199161 0.93042097 0.93848245 0.93154698 0.90810275 0.97616548\n",
      " 0.96300589 0.96807871 0.98225234 0.97192676]\n",
      "Accuracy: 0.94 (+/- 0.08)\n",
      "\n",
      "Max Depth: 6\n",
      "-----------\n",
      "Scores: [0.8426376  0.93829852 0.93842413 0.92151611 0.90707992 0.97958836\n",
      " 0.95957883 0.96912283 0.98302394 0.97297087]\n",
      "Accuracy: 0.94 (+/- 0.08)\n",
      "\n",
      "Max Depth: 7\n",
      "-----------\n",
      "Scores: [0.85103553 0.93849142 0.93874264 0.93044789 0.90739844 0.97958836\n",
      " 0.96229093 0.97616983 0.98360265 0.97367435]\n",
      "Accuracy: 0.94 (+/- 0.08)\n",
      "\n",
      "Max Depth: 8\n",
      "-----------\n",
      "Scores: [0.85297352 0.94488408 0.94274422 0.92993648 0.90778424 0.97765037\n",
      " 0.96358459 0.97577255 0.98444238 0.97257359]\n",
      "Accuracy: 0.95 (+/- 0.08)\n",
      "\n",
      "Max Depth: 9\n",
      "-----------\n",
      "Scores: [0.85297352 0.93926303 0.94944642 0.92138153 0.90734012 0.97571239\n",
      " 0.96293776 0.97770157 0.98192318 0.97264171]\n",
      "Accuracy: 0.94 (+/- 0.08)\n",
      "\n",
      "Max Depth: 10\n",
      "-----------\n",
      "Scores: [0.85038954 0.93564725 0.9550585  0.93617661 0.90830462 0.97616548\n",
      " 0.96293776 0.97564778 0.98276291 0.97476363]\n",
      "Accuracy: 0.95 (+/- 0.08)\n",
      "\n",
      "Max Depth: 11\n",
      "-----------\n",
      "Scores: [0.84974355 0.9415285  0.94995783 0.93353431 0.90926913 0.97894236\n",
      " 0.95989651 0.9783484  0.98379555 0.97346997]\n",
      "Accuracy: 0.95 (+/- 0.08)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-2f1805e86849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max Depth: {}\\n-----------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for max_depth in range(3, 15):\n",
    "    clf = RandomForestClassifier(n_estimators=max_depth, max_depth=10, random_state=0)\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='balanced_accuracy')\n",
    "    \n",
    "    print(\"Max Depth: {}\\n-----------\".format(max_depth))\n",
    "    print(\"Scores: {}\".format(scores))\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.89486189 0.95454545 0.81431967 0.92335116 0.84551396 0.9869281\n",
      " 0.97682021 0.96433878 0.98276374 0.96047548]\n",
      "accuracy: 0.93 (+/- 0.11)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.771771   0.92834841 0.68460648 0.90356284 0.89606661 0.97429479\n",
      " 0.95000115 0.96641148 0.97791743 0.96844305]\n",
      "balanced_accuracy: 0.90 (+/- 0.19)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.93607801 0.9706728  0.88466507 0.9497272  0.88888889 0.99156442\n",
      " 0.9851711  0.97651663 0.9887901  0.97380343]\n",
      "f1: 0.95 (+/- 0.08)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.8827314  0.95419417 0.80172929 0.92420838 0.85616745 0.98683024\n",
      " 0.97638846 0.96489505 0.98280247 0.96133821]\n",
      "f1_weighted: 0.93 (+/- 0.12)\n",
      "\n",
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [0.99961435 0.97685185 0.92476852 0.94020062 0.80246914 0.99768519\n",
      " 0.9996142  0.96257716 0.98688272 0.9537037 ]\n",
      "recall: 0.95 (+/- 0.11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=8, max_depth=10, random_state=0)\n",
    "print_evaluation_result(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.93644194 0.86987522 0.83541295 0.84254308 0.82560903 0.89215686\n",
      " 0.92035661 0.93164933 0.9679049  0.93402675]\n",
      "accuracy: 0.90 (+/- 0.09)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.86175711 0.73789657 0.68153801 0.80442506 0.84508236 0.77864359\n",
      " 0.83618193 0.91568694 0.93831303 0.91632229]\n",
      "balanced_accuracy: 0.83 (+/- 0.16)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.96037037 0.92079566 0.90043134 0.89538097 0.87722234 0.93386774\n",
      " 0.95046211 0.95516569 0.97945205 0.95682614]\n",
      "f1: 0.93 (+/- 0.06)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.93260334 0.85521759 0.81425971 0.8462855  0.83627031 0.8819221\n",
      " 0.91520219 0.93244301 0.96734086 0.93462975]\n",
      "f1_weighted: 0.89 (+/- 0.10)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [1.         0.98225309 0.96643519 0.875      0.80902778 0.98881173\n",
      " 0.99189815 0.94521605 0.99305556 0.94907407]\n",
      "recall: 0.95 (+/- 0.12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=0, C=1, loss='hinge')\n",
    "# clf = LinearSVC(random_state=0, C=1)\n",
    "\n",
    "print_evaluation_result(clf, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.91091782 0.89615846 0.88865546 0.79711885 0.85654262 0.92316927\n",
      " 0.91356543 0.88085234 0.96428571 0.94267707]\n",
      "accuracy: 0.90 (+/- 0.09)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.79959514 0.78311332 0.77780802 0.74214631 0.87882674 0.85164852\n",
      " 0.82761303 0.86210586 0.92828453 0.91246455]\n",
      "balanced_accuracy: 0.84 (+/- 0.12)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.94583257 0.93663004 0.93176384 0.86576648 0.90095317 0.95204196\n",
      " 0.9464684  0.92124578 0.97740649 0.96329041]\n",
      "f1: 0.93 (+/- 0.06)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.90216703 0.88688093 0.87976677 0.80335954 0.86519277 0.91981603\n",
      " 0.90854285 0.88441134 0.96350617 0.942409  ]\n",
      "f1_weighted: 0.90 (+/- 0.08)\n",
      "\n",
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [1.         0.98649691 0.97723765 0.84104938 0.83873457 0.98032407\n",
      " 0.98225309 0.89583333 0.99305556 0.96682099]\n",
      "recall: 0.95 (+/- 0.12)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "print_evaluation_result(clf, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ZKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_integer_scalar():\n",
    "    for i, k in enumerate(list(mapper.transformed_names_[:-1])):\n",
    "        scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "        if k == 'touch_duration':\n",
    "            scalar.fit(np.array(df['touch_duration']).reshape(-1, 1))\n",
    "            print(f\"\\\"duration\\\" to Pair({int(round(scalar.mean_[0]))}, {int(round(scalar.scale_[0]))})\")\n",
    "        else:  \n",
    "            scalar.fit(np.array(df[k]).reshape(-1, 1))\n",
    "            print(f\"\\\"{k}\\\" to Pair({int(round(scalar.mean_[0]))}, {int(round(scalar.scale_[0]))}),\")\n",
    "            \n",
    "        \n",
    "def get_integer_scaler():\n",
    "    avgs = []\n",
    "    stds = []\n",
    "    \n",
    "    for i, k in enumerate(list(mapper.transformed_names_[:-1])):\n",
    "        scalar = sklearn.preprocessing.StandardScaler()\n",
    "        \n",
    "        scalar.fit(np.array(df[k]).reshape(-1, 1))\n",
    "        avgs.append(int(round(scalar.mean_[0])))\n",
    "        stds.append(int(round(scalar.scale_[0])))\n",
    "    \n",
    "    return avgs, stds\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs, stds = get_integer_scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for c in list(mapper.transformed_names_[:-1]):\n",
    "#     print(c)\n",
    "    features.append(int(round(df.loc[0,c])))\n",
    "\n",
    "# features = [f + 32000000000 if f < 0 else f for f in features]\n",
    "features = [f + 3200000000000 for f in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Android App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coef(coef):\n",
    "    for i, k in enumerate(list(mapper.transformed_names_[:-1])):\n",
    "        if k == 'touch_duration':\n",
    "            print(f\"\\\"duration\\\" to {coef[0][i]}f\")\n",
    "        else:\n",
    "            print(f\"\\\"{k}\\\" to {coef[0][i]}f,\")\n",
    "\n",
    "\n",
    "def print_integer_coef(coef, digits=6, up_digits=9):\n",
    "    for i, k in enumerate(list(mapper.transformed_names_[:-1])):\n",
    "        print(f\"\\\"{k}\\\" to {int(round(coef[0][i] * 10**digits + 10**up_digits))}f,\")\n",
    "\n",
    "            \n",
    "def print_scalar(digits=6, original_digits=9):\n",
    "    for i, k in enumerate(list(mapper.transformed_names_[:-1])):\n",
    "        scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "        if k == 'touch_duration':\n",
    "            scalar.fit(np.array(df['touch_duration']).reshape(-1, 1))\n",
    "            print(f\"\\\"duration\\\" to Pair({scalar.mean_[0]}f, {scalar.scale_[0]}f)\")\n",
    "        else:  \n",
    "            scalar.fit(np.array(df[k]).reshape(-1, 1))\n",
    "            print(f\"\\\"{k}\\\" to Pair({scalar.mean_[0] * 10**(digits - original_digits)}f, {scalar.scale_[0] * 10**(digits - original_digits)}f),\")\n",
    "\n",
    "            \n",
    "def print_integer_scalar(digits=6, original_digits=9):\n",
    "    for i, k in enumerate(list(mapper.transformed_names_[:-1])):\n",
    "        scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "        if k == 'touch_duration':\n",
    "            scalar.fit(np.array(df['touch_duration']).reshape(-1, 1))\n",
    "            print(f\"\\\"duration\\\" to Pair({int(round(scalar.mean_[0]))}, {int(round(scalar.scale_[0]))})\")\n",
    "        else:  \n",
    "            scalar.fit(np.array(df[k]).reshape(-1, 1))\n",
    "            print(f\"\\\"{k}\\\" to Pair({int(round(scalar.mean_[0] * 10**(digits - original_digits)))}, {int(round(scalar.scale_[0] * 10**(digits - original_digits)))}),\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "cv_results = cross_validate(clf, X, y, cv=10, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uac_mean1_x\" to 0.5043622660731494f,\n",
      "\"uac_mean1_y\" to -0.6796020792571327f,\n",
      "\"uac_mean1_z\" to 0.13815407351208944f,\n",
      "\"uac_mean2_x\" to -0.5053552815340379f,\n",
      "\"uac_mean2_y\" to 0.6641857846463297f,\n",
      "\"uac_mean2_z\" to -0.1045658407925888f,\n",
      "\"uac_std1_x\" to 2.3948642296251235f,\n",
      "\"uac_std1_y\" to -0.2538237648221102f,\n",
      "\"uac_std1_z\" to -2.9430097745587798f,\n",
      "\"uac_std2_x\" to 0.7866253104736596f,\n",
      "\"uac_std2_y\" to 0.5951800688495773f,\n",
      "\"uac_std2_z\" to 0.029975881405415072f,\n",
      "\"uac_dev_mean1_x\" to 0.038938442647951314f,\n",
      "\"uac_dev_mean1_y\" to -0.25340396082508837f,\n",
      "\"uac_dev_mean1_z\" to 0.0750549754437046f,\n",
      "\"uac_dev_mean2_x\" to 0.3151763985495772f,\n",
      "\"uac_dev_mean2_y\" to -0.24722518245359792f,\n",
      "\"uac_dev_mean2_z\" to -0.4710242627043727f,\n",
      "\"uac_dev_std1_x\" to -1.0972558449215533f,\n",
      "\"uac_dev_std1_y\" to -0.07017995072032435f,\n",
      "\"uac_dev_std1_z\" to -0.735963755756048f,\n",
      "\"uac_dev_std2_x\" to 2.3507911237205894f,\n",
      "\"uac_dev_std2_y\" to 1.2998151101155009f,\n",
      "\"uac_dev_std2_z\" to 0.02154717634193104f,\n",
      "\"gyr_mean1_x\" to 1.8811562912541504f,\n",
      "\"gyr_mean1_y\" to 0.441215523013625f,\n",
      "\"gyr_mean1_z\" to 0.016340358813198803f,\n",
      "\"gyr_mean2_x\" to -1.1153969543649673f,\n",
      "\"gyr_mean2_y\" to -0.25247819539860755f,\n",
      "\"gyr_mean2_z\" to -0.07890711677423054f,\n",
      "\"gyr_std1_x\" to 1.681678184896682f,\n",
      "\"gyr_std1_y\" to -1.917264547560681f,\n",
      "\"gyr_std1_z\" to 1.047603267418049f,\n",
      "\"gyr_std2_x\" to 5.934699400943058f,\n",
      "\"gyr_std2_y\" to 0.1700176860483555f,\n",
      "\"gyr_std2_z\" to 0.29030335859258305f,\n",
      "\"gyr_dev_mean1_x\" to 1.9585083395364307f,\n",
      "\"gyr_dev_mean1_y\" to -0.1359917141450004f,\n",
      "\"gyr_dev_mean1_z\" to -0.14785602394683844f,\n",
      "\"gyr_dev_mean2_x\" to 2.8781052947420784f,\n",
      "\"gyr_dev_mean2_y\" to 0.41839170286414507f,\n",
      "\"gyr_dev_mean2_z\" to 0.24656311842534967f,\n",
      "\"gyr_dev_std1_x\" to 3.139204313469183f,\n",
      "\"gyr_dev_std1_y\" to 1.4451973507580995f,\n",
      "\"gyr_dev_std1_z\" to -4.404568643931888f,\n",
      "\"gyr_dev_std2_x\" to -1.0329788666289925f,\n",
      "\"gyr_dev_std2_y\" to -0.036408515700016464f,\n",
      "\"gyr_dev_std2_z\" to -1.7059157701128145f,\n"
     ]
    }
   ],
   "source": [
    "model = cv_results['estimator'][np.argmax(cv_results['test_score'])]\n",
    "print_coef(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uac_min_x\" to 1000956920f,\n",
      "\"uac_min_y\" to 1003027728f,\n",
      "\"uac_min_z\" to 1005007978f,\n",
      "\"uac_min_amp\" to 1003969366f,\n",
      "\"uac_max_x\" to 999072819f,\n",
      "\"uac_max_y\" to 997565302f,\n",
      "\"uac_max_z\" to 995964764f,\n",
      "\"uac_max_amp\" to 1000324504f,\n",
      "\"uac_mean1_x\" to 1000536781f,\n",
      "\"uac_mean1_y\" to 999392608f,\n",
      "\"uac_mean1_z\" to 999721776f,\n",
      "\"uac_mean1_amp\" to 998415390f,\n",
      "\"uac_mean2_x\" to 999630483f,\n",
      "\"uac_mean2_y\" to 1000686567f,\n",
      "\"uac_mean2_z\" to 999752957f,\n",
      "\"uac_mean2_amp\" to 995869105f,\n",
      "\"uac_std1_x\" to 1002890383f,\n",
      "\"uac_std1_y\" to 1000930144f,\n",
      "\"uac_std1_z\" to 1001131952f,\n",
      "\"uac_std1_amp\" to 1003406791f,\n",
      "\"uac_std2_x\" to 1002688018f,\n",
      "\"uac_std2_y\" to 1000518870f,\n",
      "\"uac_std2_z\" to 1001169026f,\n",
      "\"uac_std2_amp\" to 1000310298f,\n",
      "\"uac_dev_mean1_x\" to 999972019f,\n",
      "\"uac_dev_mean1_y\" to 999603038f,\n",
      "\"uac_dev_mean1_z\" to 1000200794f,\n",
      "\"uac_dev_mean1_amp\" to 999236626f,\n",
      "\"uac_dev_mean2_x\" to 1000185558f,\n",
      "\"uac_dev_mean2_y\" to 999859169f,\n",
      "\"uac_dev_mean2_z\" to 999343847f,\n",
      "\"uac_dev_mean2_amp\" to 1001030114f,\n",
      "\"uac_dev_std1_x\" to 998894311f,\n",
      "\"uac_dev_std1_y\" to 1000267178f,\n",
      "\"uac_dev_std1_z\" to 1000117317f,\n",
      "\"uac_dev_std1_amp\" to 999189826f,\n",
      "\"uac_dev_std2_x\" to 1003515940f,\n",
      "\"uac_dev_std2_y\" to 1001202017f,\n",
      "\"uac_dev_std2_z\" to 1000255556f,\n",
      "\"uac_dev_std2_amp\" to 998740623f,\n",
      "\"gyr_min_x\" to 1003014873f,\n",
      "\"gyr_min_y\" to 1003668024f,\n",
      "\"gyr_min_z\" to 1000607726f,\n",
      "\"gyr_min_amp\" to 1008603045f,\n",
      "\"gyr_max_x\" to 996420352f,\n",
      "\"gyr_max_y\" to 995707797f,\n",
      "\"gyr_max_z\" to 999123748f,\n",
      "\"gyr_max_amp\" to 1006497392f,\n",
      "\"gyr_mean1_x\" to 1000200331f,\n",
      "\"gyr_mean1_y\" to 1000731505f,\n",
      "\"gyr_mean1_z\" to 1000388979f,\n",
      "\"gyr_mean1_amp\" to 1007165327f,\n",
      "\"gyr_mean2_x\" to 1000505317f,\n",
      "\"gyr_mean2_y\" to 999885162f,\n",
      "\"gyr_mean2_z\" to 999927656f,\n",
      "\"gyr_mean2_amp\" to 1005097177f,\n",
      "\"gyr_std1_x\" to 997846923f,\n",
      "\"gyr_std1_y\" to 1002585277f,\n",
      "\"gyr_std1_z\" to 1001685277f,\n",
      "\"gyr_std1_amp\" to 1008134852f,\n",
      "\"gyr_std2_x\" to 1001453992f,\n",
      "\"gyr_std2_y\" to 999997618f,\n",
      "\"gyr_std2_z\" to 1000232094f,\n",
      "\"gyr_std2_amp\" to 998126069f,\n",
      "\"gyr_dev_mean1_x\" to 1003849174f,\n",
      "\"gyr_dev_mean1_y\" to 999980603f,\n",
      "\"gyr_dev_mean1_z\" to 999870206f,\n",
      "\"gyr_dev_mean1_amp\" to 997275749f,\n",
      "\"gyr_dev_mean2_x\" to 1001351689f,\n",
      "\"gyr_dev_mean2_y\" to 1000482805f,\n",
      "\"gyr_dev_mean2_z\" to 1000341063f,\n",
      "\"gyr_dev_mean2_amp\" to 997545353f,\n",
      "\"gyr_dev_std1_x\" to 999683003f,\n",
      "\"gyr_dev_std1_y\" to 1002927410f,\n",
      "\"gyr_dev_std1_z\" to 995830308f,\n",
      "\"gyr_dev_std1_amp\" to 999689724f,\n",
      "\"gyr_dev_std2_x\" to 998966818f,\n",
      "\"gyr_dev_std2_y\" to 1000091520f,\n",
      "\"gyr_dev_std2_z\" to 998342595f,\n",
      "\"gyr_dev_std2_amp\" to 1000715901f,\n"
     ]
    }
   ],
   "source": [
    "print_integer_coef(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34200145,  0.33303798,  0.35531744, ..., -0.3580219 ,\n",
       "        -0.38019391, -0.9257407 ],\n",
       "       [ 0.35635769,  0.33644522, -1.15966477, ..., -0.44904186,\n",
       "        -0.23260265, -0.8729696 ],\n",
       "       [ 0.46409508,  0.33816534,  0.42218635, ..., -0.36566323,\n",
       "        -0.40896313, -0.66188521],\n",
       "       ...,\n",
       "       [ 0.29492309,  0.13048792,  0.31752587, ..., -0.33051858,\n",
       "        -0.3012544 ,  0.20883791],\n",
       "       [ 0.27211474,  0.44749328,  0.37955141, ..., -0.33993809,\n",
       "        -0.2885324 , -0.79381295],\n",
       "       [ 0.34440271,  0.42220962,  0.38945404, ..., -0.31450735,\n",
       "        -0.31517376, -1.82284936]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.53579312])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uac_mean1_x\" to Pair(34516.65162001566f, 576326.8444800748f),\n",
      "\"uac_mean1_y\" to Pair(-370186.0692552214f, 1527879.2685099624f),\n",
      "\"uac_mean1_z\" to Pair(-37383.63976057294f, 1746312.4147280736f),\n",
      "\"uac_mean2_x\" to Pair(39580.90414071639f, 617791.7043897291f),\n",
      "\"uac_mean2_y\" to Pair(-376099.1364967369f, 1491830.5898873196f),\n",
      "\"uac_mean2_z\" to Pair(-27660.541683498588f, 1649299.2802535745f),\n",
      "\"uac_std1_x\" to Pair(183959.5539564302f, 423960.62350827263f),\n",
      "\"uac_std1_y\" to Pair(329310.68608901073f, 521691.2061929211f),\n",
      "\"uac_std1_z\" to Pair(518274.1504097651f, 729568.9671292837f),\n",
      "\"uac_std2_x\" to Pair(430870.9596473733f, 1029762.96606313f),\n",
      "\"uac_std2_y\" to Pair(430185.05464646354f, 627195.7788166627f),\n",
      "\"uac_std2_z\" to Pair(565359.538486775f, 819433.3941128792f),\n",
      "\"uac_dev_mean1_x\" to Pair(-24.71442798751374f, 13734.750315820862f),\n",
      "\"uac_dev_mean1_y\" to Pair(-83.57803828366964f, 35390.38260078453f),\n",
      "\"uac_dev_mean1_z\" to Pair(26.889754878037248f, 51228.99402615546f),\n",
      "\"uac_dev_mean2_x\" to Pair(226.2800861016738f, 34797.1774674752f),\n",
      "\"uac_dev_mean2_y\" to Pair(-58.05839257263473f, 30351.75859132041f),\n",
      "\"uac_dev_mean2_z\" to Pair(-165.670113140576f, 48188.4920227039f),\n",
      "\"uac_dev_std1_x\" to Pair(97494.59565591345f, 173934.266721063f),\n",
      "\"uac_dev_std1_y\" to Pair(109289.18308880659f, 127945.67678598761f),\n",
      "\"uac_dev_std1_z\" to Pair(184725.52656670052f, 243427.1530118312f),\n",
      "\"uac_dev_std2_x\" to Pair(191708.45920612f, 394550.55490194727f),\n",
      "\"uac_dev_std2_y\" to Pair(127623.50723984482f, 142712.06161797093f),\n",
      "\"uac_dev_std2_z\" to Pair(152258.7420274746f, 161501.0290193576f),\n",
      "\"gyr_mean1_x\" to Pair(927.9713382162773f, 2791090.1870129257f),\n",
      "\"gyr_mean1_y\" to Pair(-2815.965603372424f, 115219.30565088776f),\n",
      "\"gyr_mean1_z\" to Pair(-995.7999581170228f, 90980.72791077459f),\n",
      "\"gyr_mean2_x\" to Pair(-3449.620688750131f, 2632110.9807027862f),\n",
      "\"gyr_mean2_y\" to Pair(-8337.906772674161f, 132878.3386805481f),\n",
      "\"gyr_mean2_z\" to Pair(520.7963687448705f, 82920.7807289791f),\n",
      "\"gyr_std1_x\" to Pair(698973.4753280467f, 1246042.308201678f),\n",
      "\"gyr_std1_y\" to Pair(54729.838581731135f, 105518.54154118332f),\n",
      "\"gyr_std1_z\" to Pair(27058.786208456197f, 56291.09440370073f),\n",
      "\"gyr_std2_x\" to Pair(841261.0516777446f, 1506793.8555833537f),\n",
      "\"gyr_std2_y\" to Pair(48005.97455172001f, 85251.99951705689f),\n",
      "\"gyr_std2_z\" to Pair(30017.450048853923f, 52096.18230973468f),\n",
      "\"gyr_dev_mean1_x\" to Pair(-339.7518007995598f, 90491.07915896054f),\n",
      "\"gyr_dev_mean1_y\" to Pair(-341.4906548755666f, 5710.484307094821f),\n",
      "\"gyr_dev_mean1_z\" to Pair(37.44284203494015f, 2565.6956617430337f),\n",
      "\"gyr_dev_mean2_x\" to Pair(-127.92365335656368f, 84377.98154104783f),\n",
      "\"gyr_dev_mean2_y\" to Pair(-26.402740844151353f, 3763.616780258776f),\n",
      "\"gyr_dev_mean2_z\" to Pair(23.294781294082796f, 2512.6176840089624f),\n",
      "\"gyr_dev_std1_x\" to Pair(185298.73920248833f, 596003.5580403174f),\n",
      "\"gyr_dev_std1_y\" to Pair(22356.80246844314f, 37568.760240642696f),\n",
      "\"gyr_dev_std1_z\" to Pair(8405.050827228984f, 16832.410392010064f),\n",
      "\"gyr_dev_std2_x\" to Pair(197701.48998891423f, 620344.0051940846f),\n",
      "\"gyr_dev_std2_y\" to Pair(18773.90566867237f, 32262.860231163126f),\n",
      "\"gyr_dev_std2_z\" to Pair(10883.45282237443f, 18575.890800452806f),\n"
     ]
    }
   ],
   "source": [
    "print_scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uac_min_x\" to Pair(-301390, 1016818),\n",
      "\"uac_min_y\" to Pair(-923137, 1917118),\n",
      "\"uac_min_z\" to Pair(-955671, 2142766),\n",
      "\"uac_min_amp\" to Pair(974803, 1700518),\n",
      "\"uac_max_x\" to Pair(366234, 997643),\n",
      "\"uac_max_y\" to Pair(172680, 1481356),\n",
      "\"uac_max_z\" to Pair(815683, 1913007),\n",
      "\"uac_max_amp\" to Pair(2169077, 2840532),\n",
      "\"uac_mean1_x\" to Pair(34517, 576327),\n",
      "\"uac_mean1_y\" to Pair(-370186, 1527879),\n",
      "\"uac_mean1_z\" to Pair(-37384, 1746312),\n",
      "\"uac_mean1_amp\" to Pair(1490309, 2142880),\n",
      "\"uac_mean2_x\" to Pair(39581, 617792),\n",
      "\"uac_mean2_y\" to Pair(-376099, 1491831),\n",
      "\"uac_mean2_z\" to Pair(-27661, 1649299),\n",
      "\"uac_mean2_amp\" to Pair(1591608, 2124154),\n",
      "\"uac_std1_x\" to Pair(183960, 423961),\n",
      "\"uac_std1_y\" to Pair(329311, 521691),\n",
      "\"uac_std1_z\" to Pair(518274, 729569),\n",
      "\"uac_std1_amp\" to Pair(349581, 543376),\n",
      "\"uac_std2_x\" to Pair(430871, 1029763),\n",
      "\"uac_std2_y\" to Pair(430185, 627196),\n",
      "\"uac_std2_z\" to Pair(565360, 819433),\n",
      "\"uac_std2_amp\" to Pair(562330, 948103),\n",
      "\"uac_dev_mean1_x\" to Pair(-25, 13735),\n",
      "\"uac_dev_mean1_y\" to Pair(-84, 35390),\n",
      "\"uac_dev_mean1_z\" to Pair(27, 51229),\n",
      "\"uac_dev_mean1_amp\" to Pair(1343, 27353),\n",
      "\"uac_dev_mean2_x\" to Pair(226, 34797),\n",
      "\"uac_dev_mean2_y\" to Pair(-58, 30352),\n",
      "\"uac_dev_mean2_z\" to Pair(-166, 48188),\n",
      "\"uac_dev_mean2_amp\" to Pair(6507, 39232),\n",
      "\"uac_dev_std1_x\" to Pair(97495, 173934),\n",
      "\"uac_dev_std1_y\" to Pair(109289, 127946),\n",
      "\"uac_dev_std1_z\" to Pair(184726, 243427),\n",
      "\"uac_dev_std1_amp\" to Pair(154359, 236330),\n",
      "\"uac_dev_std2_x\" to Pair(191708, 394551),\n",
      "\"uac_dev_std2_y\" to Pair(127624, 142712),\n",
      "\"uac_dev_std2_z\" to Pair(152259, 161501),\n",
      "\"uac_dev_std2_amp\" to Pair(214166, 359248),\n",
      "\"gyr_min_x\" to Pair(-1133488, 3099118),\n",
      "\"gyr_min_y\" to Pair(-97351, 208522),\n",
      "\"gyr_min_z\" to Pair(-47656, 134471),\n",
      "\"gyr_min_amp\" to Pair(358010, 1189200),\n",
      "\"gyr_max_x\" to Pair(1130906, 3103357),\n",
      "\"gyr_max_y\" to Pair(95834, 205464),\n",
      "\"gyr_max_z\" to Pair(45722, 115094),\n",
      "\"gyr_max_amp\" to Pair(2236576, 3716735),\n",
      "\"gyr_mean1_x\" to Pair(928, 2791090),\n",
      "\"gyr_mean1_y\" to Pair(-2816, 115219),\n",
      "\"gyr_mean1_z\" to Pair(-996, 90981),\n",
      "\"gyr_mean1_amp\" to Pair(1422361, 2534869),\n",
      "\"gyr_mean2_x\" to Pair(-3450, 2632111),\n",
      "\"gyr_mean2_y\" to Pair(-8338, 132878),\n",
      "\"gyr_mean2_z\" to Pair(521, 82921),\n",
      "\"gyr_mean2_amp\" to Pair(1426021, 2467789),\n",
      "\"gyr_std1_x\" to Pair(698973, 1246042),\n",
      "\"gyr_std1_y\" to Pair(54730, 105519),\n",
      "\"gyr_std1_z\" to Pair(27059, 56291),\n",
      "\"gyr_std1_amp\" to Pair(585130, 1032898),\n",
      "\"gyr_std2_x\" to Pair(841261, 1506794),\n",
      "\"gyr_std2_y\" to Pair(48006, 85252),\n",
      "\"gyr_std2_z\" to Pair(30017, 52096),\n",
      "\"gyr_std2_amp\" to Pair(671011, 1162189),\n",
      "\"gyr_dev_mean1_x\" to Pair(-340, 90491),\n",
      "\"gyr_dev_mean1_y\" to Pair(-341, 5710),\n",
      "\"gyr_dev_mean1_z\" to Pair(37, 2566),\n",
      "\"gyr_dev_mean1_amp\" to Pair(680, 61596),\n",
      "\"gyr_dev_mean2_x\" to Pair(-128, 84378),\n",
      "\"gyr_dev_mean2_y\" to Pair(-26, 3764),\n",
      "\"gyr_dev_mean2_z\" to Pair(23, 2513),\n",
      "\"gyr_dev_mean2_amp\" to Pair(121, 44495),\n",
      "\"gyr_dev_std1_x\" to Pair(185299, 596004),\n",
      "\"gyr_dev_std1_y\" to Pair(22357, 37569),\n",
      "\"gyr_dev_std1_z\" to Pair(8405, 16832),\n",
      "\"gyr_dev_std1_amp\" to Pair(193510, 597338),\n",
      "\"gyr_dev_std2_x\" to Pair(197701, 620344),\n",
      "\"gyr_dev_std2_y\" to Pair(18774, 32263),\n",
      "\"gyr_dev_std2_z\" to Pair(10883, 18576),\n",
      "\"gyr_dev_std2_amp\" to Pair(208335, 621368),\n"
     ]
    }
   ],
   "source": [
    "print_integer_scalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25936, 75) (25936, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf_fit = clf.fit(X, y)\n",
    "model = SelectFromModel(clf_fit, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print(X.shape, X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['uac_min_x', 'uac_min_z', 'uac_min_amp', 'uac_max_z',\n",
       "       'uac_mean2_amp', 'uac_std1_x', 'uac_std2_x', 'gyr_min_x',\n",
       "       'gyr_min_y', 'gyr_min_amp', 'gyr_max_x', 'gyr_max_y',\n",
       "       'gyr_max_amp', 'gyr_mean1_x', 'gyr_mean1_amp', 'gyr_mean2_amp',\n",
       "       'gyr_std1_y', 'gyr_std1_z', 'gyr_std1_amp', 'gyr_std2_x',\n",
       "       'gyr_std2_amp', 'gyr_dev_mean1_x', 'gyr_dev_mean1_amp',\n",
       "       'gyr_dev_mean2_x', 'gyr_dev_std1_y', 'gyr_dev_std1_z',\n",
       "       'gyr_dev_std1_amp', 'gyr_dev_std2_x'], dtype='<U17')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_idx = model.get_support()\n",
    "columns = np.array(mapper.transformed_names_[:-1])\n",
    "columns[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17675028,  0.19052665,  0.39324847, ..., -0.4185259 ,\n",
       "        -0.46936592, -1.69382392],\n",
       "       [ 0.15900408,  0.11742983,  0.37938465, ..., -0.41800714,\n",
       "        -0.47337155, -0.00928641],\n",
       "       [ 0.21294204,  0.1325871 ,  0.37467364, ..., -0.38715986,\n",
       "        -0.46732253, -0.91441104],\n",
       "       ...,\n",
       "       [-0.44800425, -0.22760128, -1.12667692, ...,  0.40238479,\n",
       "         0.37472697, -0.31099462],\n",
       "       [-0.10771173, -0.07153073, -2.56419112, ..., -0.24318894,\n",
       "         0.189227  , -0.03442876],\n",
       "       [-0.8040029 , -0.31855747, -2.22665285, ...,  0.30122097,\n",
       "         0.19374099,  1.02154997]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39324847, -0.26767537, -0.49024066, ..., -0.42665898,\n",
       "        -0.59511831, -0.49790853],\n",
       "       [ 0.37938465, -0.26950587, -0.47363617, ..., -0.48719005,\n",
       "        -0.53385165, -0.47458571],\n",
       "       [ 0.37467364, -0.23516356, -0.49140422, ..., -0.49641443,\n",
       "        -0.47045131, -0.48109139],\n",
       "       ...,\n",
       "       [-1.12667692,  0.69423884,  1.26051772, ...,  0.84165215,\n",
       "         0.29693951,  1.4618672 ],\n",
       "       [-2.56419112,  0.89552694,  1.13094854, ...,  0.73136864,\n",
       "        -0.07742283,  1.52689143],\n",
       "       [-2.22665285,  0.83995261,  1.80090419, ...,  1.68452773,\n",
       "         0.73360171,  1.29981892]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fit = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.79141786, -0.29507643, -0.25210378,  1.04481924,  0.98598983,\n",
       "         0.09719779,  0.13420038, -0.62178492,  0.01031415,  0.03332176,\n",
       "        -0.02860757,  0.04112506, -0.19445185,  0.65959085, -0.20601792,\n",
       "         2.85905613, -0.24799277,  0.31056106, -0.27367548,  2.92008926,\n",
       "         0.98533817, -1.09629961, -1.66866334, -0.03357776, -0.25173987,\n",
       "         0.24321389, -0.59549973,  0.17193471, -0.53526486, -0.08513464,\n",
       "        -0.23883816,  1.40482872, -0.04677919, -0.14492528, -0.04099347,\n",
       "         0.89400799, -0.00842175,  0.04637913, -0.0065119 ,  0.02326304,\n",
       "         0.37654373, -0.24800079, -0.11241903,  1.22272637, -0.15471479,\n",
       "         1.59560663,  0.17523872,  1.69846379,  0.43076895, -0.30271806,\n",
       "         0.19833039,  0.79124509,  0.66143942,  0.91358111,  0.85556791,\n",
       "        -0.24429825,  1.55352265, -0.18644175,  0.83222441,  1.03000479,\n",
       "        -0.5643186 ,  0.07714657, -0.41474612, -3.89669713,  0.05422197,\n",
       "         0.08293984,  0.01158129,  0.03482541,  0.02981279]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 192,   45],\n",
       "       [  10, 3179]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_fit.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_score = clf_fit.decision_function(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 518,   86],\n",
       "       [  27, 2092]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.matmul(X_test, clf_fit.coef_.transpose()) + clf_fit.intercept_\n",
    "\n",
    "# output\n",
    "y_pred = [1. if y > 0 else 0. for y in output]\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2288828 ,  0.29578836, -0.44409819, ...,  0.56029224,\n",
       "         0.7058806 , -0.91441104],\n",
       "       [ 0.10984455,  0.11091298,  0.30138103, ..., -0.38246169,\n",
       "        -0.42799784,  1.17240407],\n",
       "       [-0.11244534,  0.03882391, -0.03287104, ...,  0.01650637,\n",
       "         0.31327942,  0.24213709],\n",
       "       ...,\n",
       "       [ 2.8859408 , -0.82018898, -0.97122909, ...,  0.13900388,\n",
       "         0.51852287,  0.99640762],\n",
       "       [-0.13435914, -1.2772015 ,  0.28452834, ...,  0.10044697,\n",
       "         2.19554359, -0.91441104],\n",
       "       [-0.11864781, -0.94893283, -0.43682114, ...,  0.474871  ,\n",
       "         1.89898956,  1.34840053]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[y_test != y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.93555094 0.95306001 0.74450386 0.90225787 0.8134284  0.99079026\n",
      " 0.98306092 0.97830609 0.96968796 0.93224368]\n",
      "accuracy: 0.92 (+/- 0.15)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.86117863 0.94550764 0.58807511 0.92430197 0.87568637 0.99039531\n",
      " 0.97538675 0.98228678 0.96942977 0.94966351]\n",
      "balanced_accuracy: 0.91 (+/- 0.23)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.95979248 0.96921278 0.84103512 0.93298024 0.86258206 0.99400271\n",
      " 0.98901099 0.98576165 0.98011696 0.95425361]\n",
      "f1: 0.95 (+/- 0.10)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.93172523 0.95358498 0.72800154 0.90689235 0.82738786 0.99082109\n",
      " 0.98304935 0.9785712  0.97003994 0.93476487]\n",
      "f1_weighted: 0.92 (+/- 0.16)\n",
      "\n",
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [0.99884304 0.95949074 0.87770062 0.88348765 0.76041667 0.99112654\n",
      " 0.98958333 0.97492284 0.96990741 0.91743827]\n",
      "recall: 0.93 (+/- 0.14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=2)\n",
    "print_evaluation_result(clf, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP (Multi-Layer Perceptron Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.91476091 0.85650624 0.81313131 0.77599525 0.8134284  0.84076055\n",
      " 0.87994056 0.9102526  0.9640416  0.94829123]\n",
      "accuracy: 0.87 (+/- 0.12)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.82041344 0.69984119 0.63126705 0.7011601  0.82516419 0.68525248\n",
      " 0.76592695 0.85756328 0.92667008 0.92142806]\n",
      "balanced_accuracy: 0.78 (+/- 0.19)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.94999084 0.91683133 0.89569683 0.85110471 0.87238408 0.90666667\n",
      " 0.92705882 0.94194541 0.9775921  0.96867192]\n",
      "f1: 0.92 (+/- 0.08)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.90978817 0.82655824 0.78379084 0.75024021 0.83278398 0.82348531\n",
      " 0.87823059 0.90119624 0.96611379 0.95333738]\n",
      "f1_weighted: 0.86 (+/- 0.13)\n",
      "\n",
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [1.         0.98611111 0.97569444 0.85108025 0.82137346 0.98109568\n",
      " 0.99421296 0.94058642 0.99074074 0.97646605]\n",
      "recall: 0.95 (+/- 0.12)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(alpha=1, max_iter=1000, activation='identity')\n",
    "print_evaluation_result(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.91743392 0.9456328  0.78342246 0.8704694  0.85442662 0.92097445\n",
      " 0.95482912 0.98008915 0.97325409 0.95185736]\n",
      "accuracy: 0.92 (+/- 0.12)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.84476841 0.91238246 0.57947979 0.8520941  0.88432206 0.87781726\n",
      " 0.90066061 0.96578611 0.9494454  0.93284442]\n",
      "balanced_accuracy: 0.87 (+/- 0.21)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.94875549 0.96623672 0.87447699 0.91233701 0.89614984 0.94648829\n",
      " 0.97301378 0.99043611 0.98294692 0.96968527]\n",
      "f1: 0.95 (+/- 0.07)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.91197614 0.94752519 0.73954331 0.87027635 0.86446691 0.9081311\n",
      " 0.95793684 0.98377696 0.97269465 0.94660077]\n",
      "f1_weighted: 0.91 (+/- 0.14)\n",
      "\n",
      "Scoring Metric: recall\n",
      "---------\n",
      "Scores: [0.99961435 0.9845679  0.95717593 0.87654321 0.85146605 0.98649691\n",
      " 0.99382716 0.99884259 0.99151235 0.95486111]\n",
      "recall: 0.96 (+/- 0.10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(alpha=1, max_iter=1000, activation='relu')\n",
    "print_evaluation_result(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fit = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0026518 , -0.00231123,  0.00114058, ..., -0.00399185,\n",
       "         -0.00081557,  0.00824428],\n",
       "        [-0.00832938,  0.01788781, -0.01624027, ...,  0.01053059,\n",
       "          0.00798046, -0.01847192],\n",
       "        [-0.04600135,  0.09737997, -0.0873595 , ...,  0.05899013,\n",
       "          0.04375023, -0.12811422],\n",
       "        ...,\n",
       "        [ 0.02550574, -0.0544871 ,  0.04860669, ..., -0.03195088,\n",
       "         -0.02417304,  0.08472809],\n",
       "        [-0.00580312,  0.01221735, -0.01083614, ...,  0.00784044,\n",
       "          0.00541839, -0.00982665],\n",
       "        [ 0.01695234, -0.03581913,  0.03237605, ..., -0.02166509,\n",
       "         -0.01633526,  0.04975283]]), array([[ 0.08930643],\n",
       "        [-0.19063661],\n",
       "        [ 0.17105821],\n",
       "        [ 0.35061924],\n",
       "        [-0.15358283],\n",
       "        [-0.28293363],\n",
       "        [-0.14207488],\n",
       "        [-0.16524062],\n",
       "        [ 0.06991162],\n",
       "        [ 0.25258654],\n",
       "        [-0.28449418],\n",
       "        [-0.10599163],\n",
       "        [ 0.27649007],\n",
       "        [-0.15969964],\n",
       "        [ 0.28904187],\n",
       "        [-0.11454038],\n",
       "        [-0.18667187],\n",
       "        [ 0.23509132],\n",
       "        [ 0.16937372],\n",
       "        [ 0.26289082],\n",
       "        [ 0.1881114 ],\n",
       "        [-0.16129141],\n",
       "        [ 0.16213284],\n",
       "        [-0.29291341],\n",
       "        [ 0.20815233],\n",
       "        [ 0.37643132],\n",
       "        [-0.00156697],\n",
       "        [ 0.16944748],\n",
       "        [-0.27272005],\n",
       "        [-0.03013249],\n",
       "        [ 0.2883897 ],\n",
       "        [-0.11262878],\n",
       "        [-0.16060552],\n",
       "        [ 0.0822821 ],\n",
       "        [-0.02356418],\n",
       "        [ 0.22523125],\n",
       "        [ 0.23804405],\n",
       "        [ 0.24756265],\n",
       "        [ 0.26237536],\n",
       "        [ 0.13968661],\n",
       "        [ 0.2141094 ],\n",
       "        [ 0.33692999],\n",
       "        [ 0.27242853],\n",
       "        [-0.31354432],\n",
       "        [-0.20793019],\n",
       "        [-0.08761524],\n",
       "        [ 0.17476109],\n",
       "        [-0.03920046],\n",
       "        [-0.23125221],\n",
       "        [ 0.11777639],\n",
       "        [-0.06090611],\n",
       "        [-0.07175373],\n",
       "        [ 0.10276335],\n",
       "        [-0.20610849],\n",
       "        [ 0.23638711],\n",
       "        [ 0.17755313],\n",
       "        [ 0.30729929],\n",
       "        [ 0.23590972],\n",
       "        [ 0.2224191 ],\n",
       "        [ 0.16384997],\n",
       "        [ 0.26221731],\n",
       "        [ 0.26949021],\n",
       "        [ 0.02095657],\n",
       "        [-0.03292956],\n",
       "        [-0.19163525],\n",
       "        [ 0.29278384],\n",
       "        [ 0.20660114],\n",
       "        [ 0.21370091],\n",
       "        [ 0.26877761],\n",
       "        [-0.22384236],\n",
       "        [ 0.04040842],\n",
       "        [-0.00685249],\n",
       "        [ 0.02406012],\n",
       "        [-0.15089014],\n",
       "        [ 0.27598998],\n",
       "        [-0.14720306],\n",
       "        [-0.00316357],\n",
       "        [-0.31014166],\n",
       "        [-0.19805929],\n",
       "        [-0.11878737],\n",
       "        [ 0.13695723],\n",
       "        [-0.06945673],\n",
       "        [-0.14789673],\n",
       "        [ 0.14671903],\n",
       "        [-0.13904068],\n",
       "        [-0.24698402],\n",
       "        [-0.26890936],\n",
       "        [-0.23577295],\n",
       "        [ 0.15331774],\n",
       "        [ 0.32783468],\n",
       "        [ 0.13954314],\n",
       "        [-0.03813728],\n",
       "        [-0.33014827],\n",
       "        [-0.32422942],\n",
       "        [-0.2288057 ],\n",
       "        [ 0.32679107],\n",
       "        [ 0.01712601],\n",
       "        [-0.11326452],\n",
       "        [-0.0848238 ],\n",
       "        [ 0.26209286]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.11563697,  0.12901277, -0.34700671, -0.22364646, -0.02973561,\n",
       "         0.28050259,  0.41449398, -0.10426473,  0.0560841 , -0.25752185,\n",
       "         0.34337259,  0.39330833, -0.02653838,  0.11686973, -0.12748676,\n",
       "         0.17552365,  0.11804824, -0.1387047 , -0.34171726, -0.26604545,\n",
       "        -0.02316204, -0.05438318, -0.14961552,  0.03181377, -0.28284224,\n",
       "        -0.33471685, -0.15572433, -0.29919853,  0.10481938,  0.14340936,\n",
       "        -0.03529199,  0.01382562,  0.12517701, -0.08208568,  0.10748344,\n",
       "        -0.35508674,  0.0883365 , -0.13691085, -0.20878271, -0.28455325,\n",
       "        -0.28009243, -0.32070472, -0.33721886,  0.09056198,  0.34432453,\n",
       "        -0.11553047, -0.35892953,  0.04018979,  0.22368239, -0.23009333,\n",
       "        -0.09608021,  0.3298748 ,  0.12245127,  0.16132106, -0.14907171,\n",
       "        -0.17775471, -0.16044844, -0.31117275, -0.17447362, -0.05452529,\n",
       "        -0.13816476, -0.3234145 , -0.10343409, -0.05255129,  0.39884727,\n",
       "        -0.07781698, -0.36233351, -0.25529562, -0.11983178,  0.28546583,\n",
       "        -0.17522205,  0.1638534 , -0.09064609,  0.14460668, -0.34735217,\n",
       "        -0.09562585,  0.11027223,  0.2881733 ,  0.32543411, -0.12010223,\n",
       "        -0.03033048, -0.04493043, -0.09295623, -0.15376673,  0.05617947,\n",
       "         0.23245069, -0.07583353,  0.18099819, -0.27725538, -0.16392568,\n",
       "        -0.29505549, -0.1176897 ,  0.1554934 ,  0.1065798 ,  0.15590651,\n",
       "        -0.29813008, -0.11433479, -0.04509068,  0.14114057, -0.3221813 ]),\n",
       " array([-0.20443589])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2515,   22],\n",
       "       [  46,  305]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_fit.predict(X_test)\n",
    "# y_pred\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2515,   22],\n",
       "       [  46,  305]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.matmul(np.matmul(X_test, clf_fit.coefs_[0]) + clf_fit.intercepts_[0], clf_fit.coefs_[1]) + clf_fit.intercepts_[1]\n",
    "# y_pred = 1 / (1 + np.exp(-output))\n",
    "\n",
    "# output\n",
    "y_pred = [1. if y > 0 else 0. for y in output]\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, clf_fit.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55605bee754d4ec782fb262aa7ac1ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr2, tpr2, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (1, 1.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (1, 1.0), (1, 1.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0), (0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(y_pred, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.09817909,  0.14022423, -0.2710823 ,  0.14658454,  0.31303232,\n",
       "         0.22022538, -0.17757525, -0.0150899 , -0.12645556, -0.15709481,\n",
       "         0.03103255,  0.18684006, -0.28118006, -0.34409314, -0.19932179,\n",
       "         0.31360177, -0.09771656,  0.06530222,  0.03205704,  0.29763413,\n",
       "         0.169806  , -0.0841407 ,  0.16715694,  0.32389112, -0.24196104,\n",
       "         0.31818908, -0.06837678,  0.15088643, -0.10969794,  0.17988545,\n",
       "         0.32977771, -0.23672955,  0.2735609 ,  0.19377495,  0.05513764,\n",
       "        -0.06925192,  0.14325775, -0.18872785,  0.10891123, -0.16790059,\n",
       "        -0.12280929, -0.27533466,  0.33470772,  0.05615536, -0.19758793,\n",
       "         0.269677  ,  0.22308008,  0.13898509, -0.03674593,  0.13068361,\n",
       "         0.22863965,  0.10038282,  0.10158403,  0.10108947, -0.17800446,\n",
       "        -0.16808938, -0.29673094,  0.1804681 ,  0.3823297 , -0.2022905 ,\n",
       "        -0.10864011, -0.24046087,  0.21374284, -0.00343896,  0.28684868,\n",
       "        -0.12803908, -0.08828574, -0.20702357,  0.2436092 , -0.09221078,\n",
       "        -0.08423174,  0.22216593,  0.14498856,  0.01319455, -0.05025393,\n",
       "         0.21063147, -0.26173153, -0.18062587,  0.24536853,  0.08197188,\n",
       "        -0.29330717,  0.31041868, -0.08942888, -0.26090707, -0.20126936,\n",
       "        -0.073363  , -0.32178894, -0.14419981,  0.15810602,  0.31813679,\n",
       "         0.07424224,  0.12090943, -0.2181473 , -0.00699945, -0.05926678,\n",
       "        -0.35168886,  0.15202133, -0.04423067,  0.29483954,  0.00071575]),\n",
       " array([-0.28649785])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Metric: accuracy\n",
      "---------\n",
      "Scores: [0.97648686 0.97372061 0.98060942 0.98060942 0.97645429 0.98891967\n",
      " 0.97229917 0.97087379 0.94729542 0.91678225]\n",
      "accuracy: 0.97 (+/- 0.04)\n",
      "\n",
      "Scoring Metric: balanced_accuracy\n",
      "---------\n",
      "Scores: [0.90217391 0.9076087  0.92307692 0.92307692 0.92857143 0.95604396\n",
      " 0.91362045 0.92222222 0.85860806 0.853663  ]\n",
      "balanced_accuracy: 0.91 (+/- 0.06)\n",
      "\n",
      "Scoring Metric: f1\n",
      "---------\n",
      "Scores: [0.88484848 0.88484848 0.92307692 0.91666667 0.87654321 0.95402299\n",
      " 0.88636364 0.88135593 0.76646707 0.69306931]\n",
      "f1: 0.87 (+/- 0.15)\n",
      "\n",
      "Scoring Metric: f1_weighted\n",
      "---------\n",
      "Scores: [0.97240244 0.97544635 0.98139373 0.98139373 0.97691007 0.98869985\n",
      " 0.97174961 0.97051996 0.95036575 0.91992402]\n",
      "f1_weighted: 0.97 (+/- 0.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_result(clf, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
